work_dir: "/model_server_home/work"
env_factories:
  factories:
    test:
      - factory: python_di.inject.context_builder.factory_ctx.FactoryCtx
        lazy: "False"
      - factory: python_di.inject.reflectable_ctx.ReflectableCtx
        lazy: "False"
      - factory: drools_py.inject.serialization_ctx.SerializationCtx
        lazy: "False"
model_server:
  port: 9991
  host: 0.0.0.0
  hf_model_endpoint:
    code_llama:
      hf_model: code_llama
      model_endpoint: /code_llama
      pipeline:
        task: feature-extraction
        model: codellama/CodeLlama-7b-hf
      pipeline_kwargs:
        do_sample: True
        top_k: 10
        temperature: 0.1
        top_p: 0.95
        num_return_sequences: 1
        eos_token_id: tokenizer.eos_token_id
        max_length: 200